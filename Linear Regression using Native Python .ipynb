{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "You will be building  - Linear Regression. But before you build a model, \n",
    "you will need to have a method to extract the data and process it in your data frames and convert to numpy.  Y0ou have already\n",
    "Complete the functions, readdata (similar to assignment 2), train, classify and LinRegaccuracy.\n",
    "I have called the functions in the main program.\n",
    "\n",
    "NASA data set, obtained from a series of aerodynamic and acoustic tests of two and three-dimensional airfoil blade \n",
    "sections conducted in an anechoic wind tunnel. The data set comprises different size NACA 0012 airfoils at various wind \n",
    "tunnel speeds and angles of attack. The span of the airfoil and the observer position were the same in all of the experiments. \n",
    "The data set has 6 attributes as given below. \n",
    "Now you will read a dataset for Machine Learning using pandas\n",
    "filename = \"airfoil_self_noise.dat.txt\"\n",
    "This is tab separated file with no headers\n",
    "Use appropriate command to read this data file and store the data into dataframe.\n",
    "After that convert it to numpy\n",
    "Then use numpy to split the data into training and test set.\n",
    "The training data should have 80% of data, and the test data should ahve 20% data.\n",
    "DO NOT USE SKLEARN LIBRARY\n",
    "Details of Data set:\n",
    "Attribute Information:\n",
    "\n",
    "This problem has the following inputs:\n",
    "(Attributes 1 to 5 form X_data) \n",
    "1. Frequency, in Hertzs. \n",
    "2. Angle of attack, in degrees. \n",
    "3. Chord length, in meters. \n",
    "4. Free-stream velocity, in meters per second. \n",
    "5. Suction side displacement thickness, in meters. \n",
    "\n",
    "The only output is (and Y_data): \n",
    "6. Scaled sound pressure level, in decibels. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Complete this function from the 2nd assignment on Pandas. Some minor modificatiosn in the parameters\n",
    "Be sure to feature scale and normalize\n",
    "'''\n",
    "def readdata(filename, cols, delim = \"\\t\"):\n",
    "    df = pd.read_csv(filename,sep='\\t',header=(0),names=cols)\n",
    "    print('===================Original Data==============================================')\n",
    "    print(df.head())\n",
    "    x=df.drop([\"ScaledSoundPressureLevel\"],axis=1)\n",
    "    y=df[\"ScaledSoundPressureLevel\"]\n",
    "    print(x.head())\n",
    "    print(\",............................................\")\n",
    "    #print(y)\n",
    "    \n",
    "    #scale the data\n",
    "    scaler = MinMaxScaler() \n",
    "    scaled_values = scaler.fit_transform(x) \n",
    "   \n",
    "    print('==========================After scaling=======================================')\n",
    "    print(scaled_values) # it is a numpy array, alternatively df.to_numpy()\n",
    "    X_data=scaled_values  #taking X all cols exept target col\n",
    "    Y_data=y.to_numpy()\n",
    "    \n",
    "    \n",
    "    num_training = int(0.8 * X_data.shape[0]) # 80% of the X data, taking the index \n",
    "    \n",
    "    ## x_data_train_1=0.80*X_data\n",
    "\n",
    "# split the actual data\n",
    "    x_data_train, x_data_test = X_data[:num_training], X_data[num_training:]\n",
    "    y_data_train, y_data_test = Y_data[:num_training], Y_data[num_training:]\n",
    "    print('==========================Train Test Split=======================================')\n",
    "    print('x_data_train',x_data_train.shape)\n",
    "    print('y_data_train',y_data_train.shape)\n",
    "    print('x_data_test',x_data_test.shape)\n",
    "    print('y_data_test',y_data_test.shape)\n",
    "\n",
    "    return x_data_train, y_data_train, x_data_test, y_data_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================Original Data==============================================\n",
      "   Frequency  AngleOfAttack  ChordLength  FreeStreamVelocity  \\\n",
      "0       1000            0.0       0.3048                71.3   \n",
      "1       1250            0.0       0.3048                71.3   \n",
      "2       1600            0.0       0.3048                71.3   \n",
      "3       2000            0.0       0.3048                71.3   \n",
      "4       2500            0.0       0.3048                71.3   \n",
      "\n",
      "   SuctionSideDisplacementThickness  ScaledSoundPressureLevel  \n",
      "0                          0.002663                   125.201  \n",
      "1                          0.002663                   125.951  \n",
      "2                          0.002663                   127.591  \n",
      "3                          0.002663                   127.461  \n",
      "4                          0.002663                   125.571  \n",
      "   Frequency  AngleOfAttack  ChordLength  FreeStreamVelocity  \\\n",
      "0       1000            0.0       0.3048                71.3   \n",
      "1       1250            0.0       0.3048                71.3   \n",
      "2       1600            0.0       0.3048                71.3   \n",
      "3       2000            0.0       0.3048                71.3   \n",
      "4       2500            0.0       0.3048                71.3   \n",
      "\n",
      "   SuctionSideDisplacementThickness  \n",
      "0                          0.002663  \n",
      "1                          0.002663  \n",
      "2                          0.002663  \n",
      "3                          0.002663  \n",
      "4                          0.002663  \n",
      ",............................................\n",
      "==========================After scaling=======================================\n",
      "[[0.04040404 0.         1.         1.         0.03900472]\n",
      " [0.0530303  0.         1.         1.         0.03900472]\n",
      " [0.07070707 0.         1.         1.         0.03900472]\n",
      " ...\n",
      " [0.19191919 0.7027027  0.27272727 0.19949495 0.90411066]\n",
      " [0.24242424 0.7027027  0.27272727 0.19949495 0.90411066]\n",
      " [0.30808081 0.7027027  0.27272727 0.19949495 0.90411066]]\n",
      "==========================Train Test Split=======================================\n",
      "x_data_train (1201, 5)\n",
      "y_data_train (1201,)\n",
      "x_data_test (301, 5)\n",
      "y_data_test (301,)\n"
     ]
    }
   ],
   "source": [
    "cols = ['Frequency', 'AngleOfAttack', 'ChordLength', 'FreeStreamVelocity', 'SuctionSideDisplacementThickness', 'ScaledSoundPressureLevel']\n",
    "x_data_train, y_data_train, x_data_test, y_data_test= readdata('airfoil_self_noise.dat.txt', cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Complete this function for training.\n",
    "\n",
    "''' \n",
    "def train( x_data_train, y_data_train, l_rate, iterations):\n",
    "    w=np.zeros(5)\n",
    "    b =np.zeros(1)\n",
    "    m=len(x_data_train)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        y_train_pred = np.dot(x_data_train,w)+b\n",
    "        #print(y_train_pred.shape)\n",
    "        \n",
    "        #(\"Calculating cost\")\n",
    "        cost=np.sum(np.power((y_train_pred-y_data_train),2))\n",
    "        dw=(1/m)*np.dot(x_data_train.T,(y_train_pred-y_data_train))\n",
    "        db=(1/m)*np.sum(y_train_pred-y_data_train)\n",
    "        \n",
    "        #Updating Weights\n",
    "        \n",
    "        w=w-l_rate*dw\n",
    " \n",
    "        #Updating Bias\n",
    "    \n",
    "        b=b-l_rate*db \n",
    "        \n",
    "    return w, b,y_train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we want to train the function using a combination of hyper parameters\n",
    "\n",
    "For the same we can pass the hyperparameters as a list or dictionary and can be called within the training funtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100, 0.01], 0.7724616539128444, 0.7585362441190382, [200, 0.001], 0.2651359067483898, 0.7585362441190382, [300, 0.0001], 0.04534107741586968, 0.7585362441190382]\n",
      "The maximum test accuracy is 0.7585362441190382 with hyperparameters [300, 0.0001]\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameter nested list for LR and epouch \n",
    "Hyperparameters = [[100,0.01],[200,0.001],[300,0.0001]]\n",
    "\n",
    "# Empty list for appending the values for different hyper parameters \n",
    "result =[]\n",
    "\n",
    "#Training function\n",
    "def train( x_data_train, y_data_train,iterations,l_rate):\n",
    "    w=np.zeros(5)\n",
    "    b =np.zeros(1)\n",
    "    m=len(x_data_train)\n",
    "    for i in range(iterations):  \n",
    "        y_train_pred = np.dot(x_data_train,w)+b\n",
    "        #print(y_train_pred.shape)   \n",
    "        #(\"Calculating cost\")\n",
    "        cost=np.sum(np.power((y_train_pred-y_data_train),2))\n",
    "        dw=(1/m)*np.dot(x_data_train.T,(y_train_pred-y_data_train))\n",
    "        db=(1/m)*np.sum(y_train_pred-y_data_train) \n",
    "        #Updating Weights\n",
    "        w=w-l_rate*dw\n",
    "        #Updating Bias\n",
    "        b=b-l_rate*db      \n",
    "    return w,b,y_train_pred \n",
    "\n",
    "#Calling hyperparameters \n",
    "for h in Hyperparameters:\n",
    "    w, b,y_train_pred=train(x_data_train,y_data_train,h[0],h[1])      \n",
    "    #TRAIN ACCURACY\n",
    "    total_error = 0\n",
    "    for i in range(0, len(y_data_train)):\n",
    "        errSet= abs((y_train_pred[i] - y_data_train[i]) / y_data_train[i])\n",
    "        total_error += errSet\n",
    "    total_error = (total_error / len(y_data_train))\n",
    "    accuracyScore_train = 1 - total_error \n",
    "    #Test Accuracy \n",
    "    total_error_1 = 0\n",
    "    for i in range(0, len(y_data_test)):\n",
    "        errSet= abs((y_pred_test[i] - y_data_test[i]) / y_data_test[i])\n",
    "        total_error_1 += errSet\n",
    "    total_error_1 = (total_error_1 / len(y_data_test))\n",
    "    accuracyScore_test = 1 - total_error_1\n",
    "    result.append(h)       \n",
    "    result.append(accuracyScore_train) \n",
    "    \n",
    "print(result)\n",
    "print(\"The maximum test accuracy is\",result[2].max(),\"with hyperparameters\",h) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.942169  ,  5.95578699,  9.16418196, 10.2627864 ,  3.23552959])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.46097981])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40.95866262, 40.99565378, 41.04744141, ..., 27.020546  ,\n",
       "       27.03978141, 27.0649354 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.9408569 ,   5.6845421 ,  -2.23351551,   2.51821057,\n",
       "       -12.16909591])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w #it =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1,), array([125.13675622]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Complete this function for Regression\n",
    "'''\n",
    "def classify(y_data_test,x_data_test, W, b):\n",
    "    print(w.shape)\n",
    "    print(b.shape)\n",
    "    print(x_data_test.shape)\n",
    "    y_pred_test = np.dot(w,x_data_test.T)+b \n",
    "    return y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "(1,)\n",
      "(301, 5)\n"
     ]
    }
   ],
   "source": [
    "y_pred_test=classify(y_data_test,x_data_test, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN ACCURACY\n",
    "def LinRegaccuracyTrain(y_data_train, y_train_pred):\n",
    "\n",
    "    total_error = 0\n",
    "    for i in range(0, len(y_data_train)):\n",
    "        errSet= abs((y_train_pred[i] - y_data_train[i]) / y_data_train[i])\n",
    "        total_error += errSet\n",
    "    total_error = (total_error / len(y_data_train))\n",
    "    accuracyScore = 1 - total_error\n",
    "    return accuracyScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04534107741586968"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test Accuracy\n",
    "LinRegaccuracyTrain(y_data_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST ACCURACY\n",
    "def LinRegaccuracy(y_data_test, y_pred_test):\n",
    "\n",
    "    total_error = 0\n",
    "    for i in range(0, len(y_data_test)):\n",
    "        errSet= abs((y_pred_test[i] - y_data_test[i]) / y_data_test[i])\n",
    "        total_error += errSet\n",
    "    total_error = (total_error / len(y_data_test))\n",
    "    accuracyScore = 1 - total_error\n",
    "    return accuracyScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.955912993729942"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test Accuracy\n",
    "LinRegaccuracy(y_data_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train:  34.908859724038535\n",
      "MSE test:  42.90191663778914\n",
      "RMSE train:  5.908372002848038\n",
      "RMSE test:  6.5499554683821435\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE train: \", mean_squared_error(y_data_train, y_train_pred))\n",
    "print(\"MSE test: \", mean_squared_error(y_data_test, y_pred_test))\n",
    "\n",
    "print(\"RMSE train: \", math.sqrt(mean_squared_error(y_data_train, y_train_pred)))\n",
    "print(\"RMSE test: \", math.sqrt(mean_squared_error(y_data_test, y_pred_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
